{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitqmindcondaa1deeb84d76f434e8c580936d5f69e0e",
   "display_name": "Python 3.7.6 64-bit ('QMIND': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import backend as K\n",
    "from keras.applications import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras import Sequential\n",
    "from keras.activations import softmax\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "\n",
    "def process_csv(csv_path):\n",
    "    frame_dict = {}\n",
    "    class_list = []\n",
    "    with open(csv_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        headers = next(csv_reader)  # Records the first row of csv\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if row[4] != \"\" and row[4] != 'isTrackView':\n",
    "                frame_dict[row[1]] = row[4]\n",
    "                class_list.append(row[4])\n",
    "\n",
    "    csv_file.close()\n",
    "    return frame_dict, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['isDriverView' 'isOtherView' 'isPitView' 'isSpectatorView']\n"
    }
   ],
   "source": [
    "frame_dict, class_list = process_csv(\"../../labels/Frame Tagger - Singapore.csv\")\n",
    "print(np.unique(class_list))\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(class_list), class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess = tf.Session()\n",
    "#tf.enable_eager_execution() \n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def weighted_accuracy(weights):\n",
    "    #weights = K.variable(weights)\n",
    "    \n",
    "    def accuracy(y_true, y_pred):\n",
    "        resIndices = K.argmax(y_pred, 1)\n",
    "        testIndices = K.argmax(y_true, 1)\n",
    "        \n",
    "        # results = np.array([np.insert(np.zeros(4), index, 1) for index in resIndices])\n",
    "\n",
    "        print(resIndices.shape)\n",
    "        print(testIndices.shape)\n",
    "        \n",
    "        conf_matrix = confusion_matrix(resIndices, testIndices)\n",
    "        \n",
    "        true_pos = np.diag(conf_matrix)\n",
    "        p = np.sum(conf_matrix, axis=0)\n",
    "        r = np.sum(conf_matrix, axis=1)\n",
    "        precision = [np.sum(true_pos[i] / p[i]) if p[i] > 0 else 0 for i in range(5)]\n",
    "        recall = [np.sum(true_pos[i] / r[i]) if r[i] > 0 else 0 for i in range(5)]\n",
    "        accuracy = np.sum(true_pos)/np.sum(conf_matrix)\n",
    "        \n",
    "        if print_results:\n",
    "            print('Accuracy: {:.2%}'.format(accuracy))\n",
    "            print('Precision: {:.2%}'.format(np.mean(precision)))\n",
    "            print('Recall: {:.2%}'.format(np.mean(recall)))\n",
    "            print('Confusion Matrix:')\n",
    "            print(conf_matrix)\n",
    "        return K.constant(accuracy)#, precision, recall\n",
    "        \n",
    "        #with sess.as_default():\n",
    "        # y_true = y_true.numpy()\n",
    "        # y_pred = y_pred.numpy()\n",
    "        # weight = weights\n",
    "        # weight = weight / K.sum(weight, axis=-1, keepdims=True)\n",
    "        # correct = np.ones_like(y_true)\n",
    "        # correct[np.arange(len(y_true)), y_pred.argmax(axis=-1)] = 0\n",
    "        # correct = np.sum(np.abs(y_true - correct) * weight, axis=-1)\n",
    "        # accuracy = np.sum(correct) / len(y_true)\n",
    "        # weight = weights\n",
    "        # weight = weight / K.sum(weight, axis=-1, keepdims=True)\n",
    "        # correct = K.ones_like(y_true)\n",
    "        # #correct[K.arange(K.int_shape(y_true)[0]), y_pred.argmax(axis=-1)] = 0\n",
    "        # correct = K.sum(K.abs(y_true - correct) * weight, axis=-1, keepdims=True)\n",
    "        # accuracy = K.mean(correct)\n",
    "        #return K.constant(accuracy)\n",
    "    return accuracy\n",
    "#print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 529 images belonging to 4 classes.\nFound 25 images belonging to 4 classes.\n"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "train_it = datagen.flow_from_directory(\"../../data_other/train\", target_size=(299, 299),\n",
    "                                       batch_size=64, class_mode=\"categorical\", color_mode=\"rgb\")\n",
    "\n",
    "test_it = datagen.flow_from_directory(\"../../data_other/test\", target_size=(299, 299),\n",
    "                                      batch_size=64, class_mode=\"categorical\", color_mode=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = InceptionV3()\n",
    "bottleneck_input = original_model.get_layer(index=0).input\n",
    "bottleneck_output = original_model.get_layer(index=-2).output\n",
    "bottleneck_model = Model(inputs=bottleneck_input, outputs=bottleneck_output)\n",
    "\n",
    "for layer in bottleneck_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(bottleneck_model)\n",
    "new_model.add(Dense(4, activation=softmax, input_dim=2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/10\n9/9 [==============================] - 48s 5s/step - loss: 0.6602 - accuracy: 0.8034\nEpoch 2/10\n9/9 [==============================] - 45s 5s/step - loss: 0.5022 - accuracy: 0.8639\nEpoch 3/10\n9/9 [==============================] - 46s 5s/step - loss: 0.4251 - accuracy: 0.8790\nEpoch 4/10\n9/9 [==============================] - 46s 5s/step - loss: 0.3174 - accuracy: 0.8658\nEpoch 5/10\n9/9 [==============================] - 44s 5s/step - loss: 0.2590 - accuracy: 0.9055\nEpoch 6/10\n9/9 [==============================] - 45s 5s/step - loss: 0.2063 - accuracy: 0.9263\nEpoch 7/10\n9/9 [==============================] - 45s 5s/step - loss: 0.2004 - accuracy: 0.9338\nEpoch 8/10\n9/9 [==============================] - 45s 5s/step - loss: 0.1604 - accuracy: 0.9509\nEpoch 9/10\n9/9 [==============================] - 50s 6s/step - loss: 0.1410 - accuracy: 0.9622\nEpoch 10/10\n9/9 [==============================] - 51s 6s/step - loss: 0.1288 - accuracy: 0.9754\n['isDriverView' 'isOtherView' 'isPitView' 'isSpectatorView']\n"
    }
   ],
   "source": [
    "# For a binary classification problem\n",
    "new_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', #weighted_categorical_crossentropy(class_weights),\n",
    "                  metrics=['accuracy'])#, weighted_accuracy(class_weights)])\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "new_model.fit_generator(train_it, class_weight=class_weights, epochs=10)\n",
    "\n",
    "print(np.unique(class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['loss', 'accuracy']\n[39.93602752685547, 0.4000000059604645]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(new_model.metrics_names)\n",
    "a = new_model.evaluate_generator(test_it)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Confusion Matrix\n[[ 0  0  5  0]\n [ 1  0  5  0]\n [ 0  0 12  0]\n [ 0  0  2  0]]\nClassification Report\n                 precision    recall  f1-score   support\n\n   isDriverView       0.00      0.00      0.00         5\n    isOtherView       0.00      0.00      0.00         6\n      isPitView       0.50      1.00      0.67        12\nisSpectatorView       0.00      0.00      0.00         2\n\n       accuracy                           0.48        25\n      macro avg       0.12      0.25      0.17        25\n   weighted avg       0.24      0.48      0.32        25\n\nConfusion Matrix _ Train\n[[ 12   0 445   0]\n [  0   0  22   0]\n [  3   0  41   0]\n [  0   0   6   0]]\n"
    }
   ],
   "source": [
    "#print(test_it.samples)\n",
    "#print(train_it.samples)\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = new_model.predict_generator(test_it, test_it.samples // 64+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_it.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = np.unique(class_list)\n",
    "print(classification_report(test_it.classes, y_pred, target_names=target_names))\n",
    "\n",
    "Y_pred = new_model.predict_generator(train_it, train_it.samples // 64+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix _ Train')\n",
    "print(confusion_matrix(train_it.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save(\"OtherViewModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}