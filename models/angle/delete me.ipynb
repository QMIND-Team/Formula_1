{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import backend as K\n",
        "from keras.applications import InceptionV3\n",
        "from keras.models import Model\n",
        "from keras import Sequential\n",
        "from keras.activations import softmax\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "\n",
        "def process_csv(csv_path):\n",
        "    frame_dict = {}\n",
        "    class_list = []\n",
        "    with open(csv_path) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        headers = next(csv_reader)  # Records the first row of csv\n",
        "\n",
        "        for row in csv_reader:\n",
        "            if row[4] != \"\":\n",
        "                frame_dict[row[1]] = row[4]\n",
        "                class_list.append(row[4])\n",
        "\n",
        "    csv_file.close()\n",
        "    return frame_dict, class_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frame_dict, class_list = process_csv(\"../../labels/Frame Tagger - Singapore.csv\")\n",
        "print(np.unique(class_list))\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(class_list), class_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "original_model = InceptionV3()\n",
        "bottleneck_input = original_model.get_layer(index=0).input\n",
        "bottleneck_output = original_model.get_layer(index=-2).output\n",
        "bottleneck_model = Model(inputs=bottleneck_input, outputs=bottleneck_output)\n",
        "\n",
        "for layer in bottleneck_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "new_model = Sequential()\n",
        "new_model.add(bottleneck_model)\n",
        "new_model.add(Dense(5, activation=softmax, input_dim=2048))\n",
        "\n",
        "#sess = tf.Session()\n",
        "#tf.enable_eager_execution() \n",
        "\n",
        "def weighted_categorical_crossentropy(weights):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy\n",
        "    \n",
        "    Variables:\n",
        "        weights: numpy array of shape (C,) where C is the number of classes\n",
        "    \n",
        "    Usage:\n",
        "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
        "        loss = weighted_categorical_crossentropy(weights)\n",
        "        model.compile(loss=loss,optimizer='adam')\n",
        "    \"\"\"\n",
        "    \n",
        "    weights = K.variable(weights)\n",
        "        \n",
        "    def loss(y_true, y_pred):\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = y_true * K.log(y_pred) * weights\n",
        "        loss = -K.sum(loss, -1)\n",
        "        return loss\n",
        "    \n",
        "    return loss\n",
        "\n",
        "def weighted_accuracy(weights):\n",
        "    #weights = K.variable(weights)\n",
        "    \n",
        "    def accuracy(y_true, y_pred):\n",
        "        resIndices = K.argmax(y_pred, 1)\n",
        "        testIndices = K.argmax(y_true, 1)\n",
        "        \n",
        "        # results = np.array([np.insert(np.zeros(4), index, 1) for index in resIndices])\n",
        "\n",
        "        print(resIndices.shape)\n",
        "        print(testIndices.shape)\n",
        "        \n",
        "        conf_matrix = confusion_matrix(resIndices, testIndices)\n",
        "        \n",
        "        true_pos = np.diag(conf_matrix)\n",
        "        p = np.sum(conf_matrix, axis=0)\n",
        "        r = np.sum(conf_matrix, axis=1)\n",
        "        precision = [np.sum(true_pos[i] / p[i]) if p[i] > 0 else 0 for i in range(5)]\n",
        "        recall = [np.sum(true_pos[i] / r[i]) if r[i] > 0 else 0 for i in range(5)]\n",
        "        accuracy = np.sum(true_pos)/np.sum(conf_matrix)\n",
        "        \n",
        "        if print_results:\n",
        "            print('Accuracy: {:.2%}'.format(accuracy))\n",
        "            print('Precision: {:.2%}'.format(np.mean(precision)))\n",
        "            print('Recall: {:.2%}'.format(np.mean(recall)))\n",
        "            print('Confusion Matrix:')\n",
        "            print(conf_matrix)\n",
        "        return K.constant(accuracy)#, precision, recall\n",
        "        \n",
        "        #with sess.as_default():\n",
        "        # y_true = y_true.numpy()\n",
        "        # y_pred = y_pred.numpy()\n",
        "        # weight = weights\n",
        "        # weight = weight / K.sum(weight, axis=-1, keepdims=True)\n",
        "        # correct = np.ones_like(y_true)\n",
        "        # correct[np.arange(len(y_true)), y_pred.argmax(axis=-1)] = 0\n",
        "        # correct = np.sum(np.abs(y_true - correct) * weight, axis=-1)\n",
        "        # accuracy = np.sum(correct) / len(y_true)\n",
        "        # weight = weights\n",
        "        # weight = weight / K.sum(weight, axis=-1, keepdims=True)\n",
        "        # correct = K.ones_like(y_true)\n",
        "        # #correct[K.arange(K.int_shape(y_true)[0]), y_pred.argmax(axis=-1)] = 0\n",
        "        # correct = K.sum(K.abs(y_true - correct) * weight, axis=-1, keepdims=True)\n",
        "        # accuracy = K.mean(correct)\n",
        "        #return K.constant(accuracy)\n",
        "    return accuracy\n",
        "\n",
        "# For a binary classification problem\n",
        "new_model.compile(optimizer='rmsprop',\n",
        "                  loss=weighted_categorical_crossentropy(class_weights),\n",
        "                  metrics=['accuracy', weighted_accuracy(class_weights)])\n",
        "\n",
        "datagen = ImageDataGenerator()\n",
        "train_it = datagen.flow_from_directory(\"../../data/train\", target_size=(299, 299),\n",
        "                                       batch_size=64, class_mode=\"categorical\", color_mode=\"rgb\")\n",
        "\n",
        "test_it = datagen.flow_from_directory(\"../../data/test\", target_size=(299, 299),\n",
        "                                      batch_size=64, class_mode=\"categorical\", color_mode=\"rgb\")\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "new_model.fit_generator(train_it, class_weight=class_weights, epochs=1)\n",
        "\n",
        "print(np.unique(class_list))\n",
        "print(class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(new_model.metrics_names)\n",
        "a = new_model.evaluate_generator(test_it)\n",
        "print(a)\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "Y_pred = new_model.predict_generator(test_it, 1326 // 64+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_it.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = np.unique(class_list)\n",
        "print(classification_report(test_it.classes, y_pred, target_names=target_names))\n",
        "\n",
        "Y_pred = new_model.predict_generator(train_it, 5721 // 64+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix _ Train')\n",
        "print(confusion_matrix(train_it.classes, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "tf.keras.model.save(\"CameraAngleModel.h5\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.7.6-final"
    },
    "kernelspec": {
      "name": "python37664bitqmindcondaa1deeb84d76f434e8c580936d5f69e0e",
      "language": "python",
      "display_name": "Python 3.7.6 64-bit ('QMIND': conda)"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}